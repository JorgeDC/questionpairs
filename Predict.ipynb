{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Merge\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word2vec\n",
      "done loading word2vec\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = 'wiki.nl/wiki.nl.vec'\n",
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']  \n",
    "# '<unk>' will never be used, it is only a placeholder for the \n",
    "# [0, 0, ....0] embedding\n",
    "\n",
    "print(\"loading word2vec\")\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE,binary=False)\n",
    "print(\"done loading word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question1  \\\n",
      "0                      Het moet altijd goed weer zijn   \n",
      "1   Ik vind dat het wegdek in de nieuwstraat moet ...   \n",
      "2   het wegdek in de nieuwstraat moet hersteld worden   \n",
      "3   ik stel voor dat er een volwaardige mantelzorg...   \n",
      "4   ik stel voor dat er een volwaardige mantelzorg...   \n",
      "5   ik stel voor dat iedere werknemer een bonus kr...   \n",
      "6   ik stel voor dat iedere werknemer een bonus kr...   \n",
      "7                   ik wil dat iedereen opslag krijgt   \n",
      "8                                ik wil 300 euro meer   \n",
      "9                                ik wil 300 euro meer   \n",
      "10  ik stel voor dat er mogelijkheid is tot nachto...   \n",
      "\n",
      "                                            question2  \n",
      "0                      Het moet altijd goed weer zijn  \n",
      "1   het wegdek in de nieuwstraat moet vernieuwd wo...  \n",
      "2   Het nachtlawaai in de nieuwstraat moet beperkt...  \n",
      "3   Ik weet dat in Lo reeds een mantelzorgpremie b...  \n",
      "4   ik stel voor dat mantelzorgers een financiële ...  \n",
      "5   ik stel voor dat iedere werknemer een financië...  \n",
      "6   ik stel voor dat iedere werknemer tweehonderd ...  \n",
      "7                ik wil dat iedereen een bonus krijgt  \n",
      "8                              ik wil 300 euro minder  \n",
      "9          ik wil 300 euro meer geld op mijn rekening  \n",
      "10  ik stel voor dat er mogelijkheid is tot nachto...  \n"
     ]
    }
   ],
   "source": [
    "#TRAIN_CSV = \"dutch_data/dutch_formatted_small.csv\"\n",
    "PREDICT_CSV = \"dutch_data/predict_test.csv\"\n",
    "\n",
    "EMBEDDING_FILE = 'wiki.nl/wiki.nl.vec'\n",
    "\n",
    "\n",
    "predict_df = pd.read_csv(PREDICT_CSV)\n",
    "print(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substitute_thousands(text):\n",
    "    matches = re.finditer(r'[0-9]+(?P<thousands>\\s{0,2}k\\b)', text, flags=re.I)\n",
    "    result = ''\n",
    "    len_offset = 0\n",
    "    for match in matches:\n",
    "        result += '{}000'.format(text[len(result)-len_offset:match.start('thousands')])\n",
    "        len_offset += 3 - (match.end('thousands') - match.start('thousands'))\n",
    "    result += text[len(result)-len_offset:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/JorgeDeCorte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "begin sets\n",
      "end sets\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "print(\"begin sets\")\n",
    "stops = set(stopwords.words('dutch'))\n",
    "print(\"end sets\")\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = substitute_thousands(text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "\n",
    "    text = text.split()\n",
    "    #print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1    Het moet altijd goed weer zijn\n",
      "question2    Het moet altijd goed weer zijn\n",
      "Name: 0, dtype: object\n",
      "question1    Ik vind dat het wegdek in de nieuwstraat moet ...\n",
      "question2    het wegdek in de nieuwstraat moet vernieuwd wo...\n",
      "Name: 1, dtype: object\n",
      "question1    het wegdek in de nieuwstraat moet hersteld worden\n",
      "question2    Het nachtlawaai in de nieuwstraat moet beperkt...\n",
      "Name: 2, dtype: object\n",
      "question1    ik stel voor dat er een volwaardige mantelzorg...\n",
      "question2    Ik weet dat in Lo reeds een mantelzorgpremie b...\n",
      "Name: 3, dtype: object\n",
      "question1    ik stel voor dat er een volwaardige mantelzorg...\n",
      "question2    ik stel voor dat mantelzorgers een financiële ...\n",
      "Name: 4, dtype: object\n",
      "question1    ik stel voor dat iedere werknemer een bonus kr...\n",
      "question2    ik stel voor dat iedere werknemer een financië...\n",
      "Name: 5, dtype: object\n",
      "question1    ik stel voor dat iedere werknemer een bonus kr...\n",
      "question2    ik stel voor dat iedere werknemer tweehonderd ...\n",
      "Name: 6, dtype: object\n",
      "question1       ik wil dat iedereen opslag krijgt\n",
      "question2    ik wil dat iedereen een bonus krijgt\n",
      "Name: 7, dtype: object\n",
      "question1      ik wil 300 euro meer\n",
      "question2    ik wil 300 euro minder\n",
      "Name: 8, dtype: object\n",
      "question1                          ik wil 300 euro meer\n",
      "question2    ik wil 300 euro meer geld op mijn rekening\n",
      "Name: 9, dtype: object\n",
      "question1    ik stel voor dat er mogelijkheid is tot nachto...\n",
      "question2    ik stel voor dat er mogelijkheid is tot nachto...\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "questions_cols = ['question1', 'question2']\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over the questions only of both training and test datasets\n",
    "for dataset in [predict_df]:\n",
    "    for index, row in dataset.iterrows():\n",
    "        print(row)\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions_cols:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in text_to_word_list(row[question]):\n",
    "                # Check for unwanted words\n",
    "                if word in stops and word not in word2vec.vocab:\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    q2n.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    q2n.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions with lists of word indices\n",
    "            dataset.set_value(index, question, q2n)\n",
    "            \n",
    "\n",
    "embedding_dim = 300\n",
    "# This will be the embedding matrix\n",
    "embeddings = 1 * np.random.randn(208423, embedding_dim)  \n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "\n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': 0                                    [1, 2, 3, 4, 5, 6]\n",
      "1               [7, 8, 9, 1, 10, 11, 12, 13, 2, 14, 15]\n",
      "2                        [1, 10, 11, 12, 13, 2, 14, 15]\n",
      "3     [7, 20, 21, 9, 22, 23, 24, 25, 26, 27, 28, 29,...\n",
      "4     [7, 20, 21, 9, 22, 23, 24, 25, 26, 27, 28, 29,...\n",
      "5        [7, 20, 21, 9, 80, 81, 23, 76, 82, 26, 83, 28]\n",
      "6        [7, 20, 21, 9, 80, 81, 23, 76, 82, 26, 84, 28]\n",
      "7                                [7, 86, 9, 87, 88, 82]\n",
      "8                                   [7, 86, 89, 28, 85]\n",
      "9                                   [7, 86, 89, 28, 85]\n",
      "10    [7, 20, 21, 9, 22, 95, 66, 96, 97, 98, 99, 11,...\n",
      "Name: question1, dtype: object, 'right': 0                                    [1, 2, 3, 4, 5, 6]\n",
      "1                        [1, 10, 11, 12, 13, 2, 16, 15]\n",
      "2                    [1, 17, 11, 12, 13, 2, 18, 15, 19]\n",
      "3     [7, 42, 9, 11, 43, 44, 23, 25, 45, 46, 47, 48,...\n",
      "4            [7, 20, 21, 9, 34, 23, 75, 76, 77, 78, 79]\n",
      "5                [7, 20, 21, 9, 80, 81, 23, 75, 76, 82]\n",
      "6        [7, 20, 21, 9, 80, 81, 84, 28, 29, 30, 85, 82]\n",
      "7                            [7, 86, 9, 87, 23, 76, 82]\n",
      "8                                   [7, 86, 89, 28, 90]\n",
      "9                   [7, 86, 89, 28, 85, 91, 92, 93, 94]\n",
      "10    [7, 20, 21, 9, 22, 95, 66, 96, 97, 21, 98, 99,...\n",
      "Name: question2, dtype: object}\n",
      "{'left': array([[  0,   0,   0, ...,   4,   5,   6],\n",
      "       [  0,   0,   0, ...,   2,  14,  15],\n",
      "       [  0,   0,   0, ...,   2,  14,  15],\n",
      "       ..., \n",
      "       [  0,   0,   0, ...,  89,  28,  85],\n",
      "       [  0,   0,   0, ...,  89,  28,  85],\n",
      "       [  0,   0,   0, ..., 109,  57, 110]], dtype=int32), 'right': array([[  0,   0,   0, ...,   4,   5,   6],\n",
      "       [  0,   0,   0, ...,   2,  16,  15],\n",
      "       [  0,   0,   0, ...,  18,  15,  19],\n",
      "       ..., \n",
      "       [  0,   0,   0, ...,  89,  28,  90],\n",
      "       [  0,   0,   0, ...,  92,  93,  94],\n",
      "       [  0,   0,   0, ..., 109,  57, 114]], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 243\n",
    "X = predict_df[questions_cols]\n",
    "# Split to dicts\n",
    "X_predict = {'left': predict_df.question1, 'right': predict_df.question2}\n",
    "\n",
    "print(X_predict)\n",
    "\n",
    "# Zero padding\n",
    "for dataset, side in itertools.product([X_predict], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
    "\n",
    "print(X_predict)\n",
    "# Make sure everything is ok\n",
    "assert X_predict['left'].shape == X_predict['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JorgeDeCorte/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:32: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "# Model variables\n",
    "n_hidden = 50\n",
    "gradient_clipping_norm = 1.25\n",
    "batch_size = 256\n",
    "n_epoch = 2\n",
    "\n",
    "#del malstm\n",
    "K.clear_session()\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Merge(mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]), output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "malstm.load_weights(\"weights-improvement-34-0.79.hdf5\")\n",
    "\n",
    "prediction = malstm.predict([X_predict['left'], X_predict['right']])\n",
    "#print(prediction)\n",
    "#print(predict_df)\n",
    "\n",
    "del malstm\n",
    "# Adadelta optimizer, with gradient clipping by norm\n",
    "#optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
    "\n",
    "#malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Het moet altijd goed weer zijn\n",
      "Het moet altijd goed weer zijn\n",
      "1.0\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n",
      "Ik vind dat het wegdek in de nieuwstraat moet hersteld worden\n",
      "het wegdek in de nieuwstraat moet vernieuwd worden\n",
      "0.681675\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n",
      "het wegdek in de nieuwstraat moet hersteld worden\n",
      "Het nachtlawaai in de nieuwstraat moet beperkt worden!\n",
      "0.562189\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n",
      "ik stel voor dat er een volwaardige mantelzorgpremie van 50 euro per maand wordt ingevoerd voor alle mantelzorgers in onze gemeente die zorgen voor een zwaar zorgbehoevende persoon\n",
      "Ik weet dat in Lo reeds een mantelzorgpremie bestaat, doch  Ziekenzorg CM  vraagt deze te verhogen.Deze premie moet administratief makkelijk te bekomen zijn aan de hand van soepele voorwaarden die zo weinig mogelijk mantelzorgers uitsluiten.Deze maatregel is de goedkoopste en meest efficente om de thuiszorg in de toekomst te organiseren.\n",
      "0.11879\n",
      "Niet dubbel...\n",
      "\n",
      "\n",
      "ik stel voor dat er een volwaardige mantelzorgpremie van 50 euro per maand wordt ingevoerd voor alle mantelzorgers in onze gemeente die zorgen voor een zwaar zorgbehoevende persoon\n",
      "ik stel voor dat mantelzorgers een financiële bonus zouden moeten krijgen.\n",
      "0.348395\n",
      "Niet dubbel...\n",
      "\n",
      "\n",
      "ik stel voor dat iedere werknemer een bonus krijgt van 200 euro\n",
      "ik stel voor dat iedere werknemer een financiële bonus krijgt\n",
      "0.336588\n",
      "Niet dubbel...\n",
      "\n",
      "\n",
      "ik stel voor dat iedere werknemer een bonus krijgt van tweehonderd euro\n",
      "ik stel voor dat iedere werknemer tweehonderd euro per maand meer krijgt\n",
      "0.5794\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n",
      "ik wil dat iedereen opslag krijgt\n",
      "ik wil dat iedereen een bonus krijgt\n",
      "0.810983\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n",
      "ik wil 300 euro meer\n",
      "ik wil 300 euro minder\n",
      "0.782914\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n",
      "ik wil 300 euro meer\n",
      "ik wil 300 euro meer geld op mijn rekening\n",
      "0.290788\n",
      "Niet dubbel...\n",
      "\n",
      "\n",
      "ik stel voor dat er mogelijkheid is tot nachtopvang kinderen. Wie in shiften werkt, nachtdiensten presteerd alsook weekends kan nergens terecht. Tekort aan opvangmogelijkheden.\n",
      "ik stel voor dat er mogelijkheid is tot nachtopvang voor kinderen. Wie in shiften werkt, nachtdiensten presteerd en weekends kunnen nergens terecht. Duidelijk ook tekort aan opvangplaatsen\n",
      "0.595829\n",
      "Dubbele vraag gevonden!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_to_print = pd.read_csv(PREDICT_CSV)\n",
    "for index, row in predict_to_print.iterrows():\n",
    "    print(row[0])\n",
    "    print(row[1])\n",
    "    pred = prediction[index][0]\n",
    "    print(pred)\n",
    "    if pred > 0.5:\n",
    "        print(\"Dubbele vraag gevonden!\")\n",
    "    else:\n",
    "        print(\"Niet dubbel...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
